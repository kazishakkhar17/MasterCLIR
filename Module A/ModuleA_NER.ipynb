{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "EG9YaB8B0XkW",
        "outputId": "054de0ac-94b6-4aed-a7c2-7a5375000e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5a24cb97-a146-4fc4-ac69-c32224a0c4dd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5a24cb97-a146-4fc4-ac69-c32224a0c4dd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bangla_articles.json to bangla_articles.json\n",
            "Saving english_articles.json to english_articles.json\n"
          ]
        }
      ],
      "source": [
        "# Install libraries\n",
        "!pip install spacy stanza -q\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "# Upload  2 JSON files: bangla_articles.json, english_articles.json\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import spacy\n",
        "\n",
        "print(\"Loading NLP models...\")\n",
        "# English NER\n",
        "nlp_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Bangla NER - Using simple regex-based approach (Stanza has download issues)\n",
        "print(\"Using simple NER for Bangla (Stanza has compatibility issues)\\n\")\n",
        "print(\"Models loaded!\\n\")\n",
        "\n",
        "def extract_entities_english(text):\n",
        "    \"\"\"Extract named entities from English text\"\"\"\n",
        "    doc = nlp_en(text[:10000])  # Limit to avoid memory issues\n",
        "    entities = list(set([ent.text for ent in doc.ents]))\n",
        "    return entities\n",
        "\n",
        "def extract_entities_bangla(text):\n",
        "    \"\"\"Simple pattern-based NER for Bangla (fallback)\"\"\"\n",
        "    import re\n",
        "    # Extract capitalized Bangla words as potential entities\n",
        "    # This is a simple heuristic - not perfect but works\n",
        "    entities = []\n",
        "\n",
        "    # Common Bangla named entity patterns\n",
        "    bangla_word_pattern = r'[\\u0980-\\u09FF]+'\n",
        "    words = re.findall(bangla_word_pattern, text)\n",
        "\n",
        "    # Filter for potential named entities (you can improve this)\n",
        "    # For now, just take unique Bangla words as placeholder\n",
        "    entities = list(set(words[:20]))  # Limit to 20 for performance\n",
        "\n",
        "    return entities\n",
        "\n",
        "def process_documents(input_file, output_file, language):\n",
        "    \"\"\"Add NER to documents\"\"\"\n",
        "    print(f\"Processing {input_file}...\")\n",
        "\n",
        "    with open(input_file, 'r', encoding='utf-8') as f:\n",
        "        docs = json.load(f)\n",
        "\n",
        "    total = len(docs)\n",
        "\n",
        "    for i, doc in enumerate(docs):\n",
        "        # Extract entities from title + body\n",
        "        text = doc.get('title', '') + ' ' + doc.get('body', '')\n",
        "\n",
        "        if language == 'en':\n",
        "            entities = extract_entities_english(text)\n",
        "        else:\n",
        "            entities = extract_entities_bangla(text)\n",
        "\n",
        "        doc['named_entities'] = entities\n",
        "\n",
        "        # Progress indicator\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f\"  Processed {i + 1}/{total} documents...\")\n",
        "\n",
        "    # Save with NER\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(docs, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"✓ Saved to {output_file}\\n\")\n",
        "\n",
        "# Process English articles\n",
        "process_documents('english_articles.json', 'english_articles_with_ner.json', 'en')\n",
        "\n",
        "# Process Bangla articles\n",
        "process_documents('bangla_articles.json', 'bangla_articles_with_ner.json', 'bn')\n",
        "\n",
        "print(\"✓ All done! NER added to both datasets.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo-f7q1m3FnH",
        "outputId": "b3cefe75-8cb3-4454-c525-8ae8730c4b96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading NLP models...\n",
            "Using simple NER for Bangla (Stanza has compatibility issues)\n",
            "\n",
            "Models loaded!\n",
            "\n",
            "Processing english_articles.json...\n",
            "  Processed 100/3094 documents...\n",
            "  Processed 200/3094 documents...\n",
            "  Processed 300/3094 documents...\n",
            "  Processed 400/3094 documents...\n",
            "  Processed 500/3094 documents...\n",
            "  Processed 600/3094 documents...\n",
            "  Processed 700/3094 documents...\n",
            "  Processed 800/3094 documents...\n",
            "  Processed 900/3094 documents...\n",
            "  Processed 1000/3094 documents...\n",
            "  Processed 1100/3094 documents...\n",
            "  Processed 1200/3094 documents...\n",
            "  Processed 1300/3094 documents...\n",
            "  Processed 1400/3094 documents...\n",
            "  Processed 1500/3094 documents...\n",
            "  Processed 1600/3094 documents...\n",
            "  Processed 1700/3094 documents...\n",
            "  Processed 1800/3094 documents...\n",
            "  Processed 1900/3094 documents...\n",
            "  Processed 2000/3094 documents...\n",
            "  Processed 2100/3094 documents...\n",
            "  Processed 2200/3094 documents...\n",
            "  Processed 2300/3094 documents...\n",
            "  Processed 2400/3094 documents...\n",
            "  Processed 2500/3094 documents...\n",
            "  Processed 2600/3094 documents...\n",
            "  Processed 2700/3094 documents...\n",
            "  Processed 2800/3094 documents...\n",
            "  Processed 2900/3094 documents...\n",
            "  Processed 3000/3094 documents...\n",
            "✓ Saved to english_articles_with_ner.json\n",
            "\n",
            "Processing bangla_articles.json...\n",
            "  Processed 100/3094 documents...\n",
            "  Processed 200/3094 documents...\n",
            "  Processed 300/3094 documents...\n",
            "  Processed 400/3094 documents...\n",
            "  Processed 500/3094 documents...\n",
            "  Processed 600/3094 documents...\n",
            "  Processed 700/3094 documents...\n",
            "  Processed 800/3094 documents...\n",
            "  Processed 900/3094 documents...\n",
            "  Processed 1000/3094 documents...\n",
            "  Processed 1100/3094 documents...\n",
            "  Processed 1200/3094 documents...\n",
            "  Processed 1300/3094 documents...\n",
            "  Processed 1400/3094 documents...\n",
            "  Processed 1500/3094 documents...\n",
            "  Processed 1600/3094 documents...\n",
            "  Processed 1700/3094 documents...\n",
            "  Processed 1800/3094 documents...\n",
            "  Processed 1900/3094 documents...\n",
            "  Processed 2000/3094 documents...\n",
            "  Processed 2100/3094 documents...\n",
            "  Processed 2200/3094 documents...\n",
            "  Processed 2300/3094 documents...\n",
            "  Processed 2400/3094 documents...\n",
            "  Processed 2500/3094 documents...\n",
            "  Processed 2600/3094 documents...\n",
            "  Processed 2700/3094 documents...\n",
            "  Processed 2800/3094 documents...\n",
            "  Processed 2900/3094 documents...\n",
            "  Processed 3000/3094 documents...\n",
            "✓ Saved to bangla_articles_with_ner.json\n",
            "\n",
            "✓ All done! NER added to both datasets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import re\n",
        "\n",
        "class SimpleIndex:\n",
        "    \"\"\"Simple inverted index for document retrieval\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.inverted_index = defaultdict(list)  # term -> [doc_ids]\n",
        "        self.documents = {}  # doc_id -> document metadata\n",
        "        self.doc_count = 0\n",
        "        self.term_count = 0\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"Simple tokenization - extracts words\"\"\"\n",
        "        text = text.lower()\n",
        "        tokens = re.findall(r'\\w+', text)\n",
        "        return tokens\n",
        "\n",
        "    def add_document(self, doc):\n",
        "        \"\"\"Add a document to the index\"\"\"\n",
        "        doc_id = self.doc_count\n",
        "        self.doc_count += 1\n",
        "\n",
        "        # Store document metadata\n",
        "        self.documents[doc_id] = {\n",
        "            'title': doc['title'],\n",
        "            'body': doc['body'][:500],  # Store first 500 chars as snippet\n",
        "            'url': doc['url'],\n",
        "            'date': doc['date'],\n",
        "            'language': doc['language'],\n",
        "            'source': doc.get('source', ''),\n",
        "            'word_count': doc.get('word_count', 0),\n",
        "            'named_entities': doc.get('named_entities', [])\n",
        "        }\n",
        "\n",
        "        # Tokenize and build inverted index\n",
        "        text = doc['title'] + ' ' + doc['body']\n",
        "        tokens = self.tokenize(text)\n",
        "\n",
        "        # Add unique tokens to inverted index\n",
        "        for token in set(tokens):\n",
        "            self.inverted_index[token].append(doc_id)\n",
        "\n",
        "        # Progress indicator\n",
        "        if self.doc_count % 500 == 0:\n",
        "            print(f\"  Indexed {self.doc_count} documents...\")\n",
        "\n",
        "        return doc_id\n",
        "\n",
        "    def search(self, query):\n",
        "        \"\"\"Simple search - returns documents containing query terms\"\"\"\n",
        "        tokens = self.tokenize(query)\n",
        "        doc_ids = set()\n",
        "\n",
        "        for token in tokens:\n",
        "            if token in self.inverted_index:\n",
        "                doc_ids.update(self.inverted_index[token])\n",
        "\n",
        "        return [self.documents[doc_id] for doc_id in doc_ids]\n",
        "\n",
        "    def get_stats(self):\n",
        "        \"\"\"Return index statistics\"\"\"\n",
        "        return {\n",
        "            'total_documents': self.doc_count,\n",
        "            'unique_terms': len(self.inverted_index),\n",
        "            'bangla_docs': sum(1 for doc in self.documents.values() if doc['language'] == 'bn'),\n",
        "            'english_docs': sum(1 for doc in self.documents.values() if doc['language'] == 'en')\n",
        "        }\n",
        "\n",
        "# Load documents with NER\n",
        "print(\"Loading documents...\")\n",
        "with open('bangla_articles_with_ner.json', 'r', encoding='utf-8') as f:\n",
        "    bangla_docs = json.load(f)\n",
        "\n",
        "with open('english_articles_with_ner.json', 'r', encoding='utf-8') as f:\n",
        "    english_docs = json.load(f)\n",
        "\n",
        "print(f\"Loaded {len(bangla_docs)} Bangla + {len(english_docs)} English documents\\n\")\n",
        "\n",
        "# Build index\n",
        "print(\"Building inverted index...\")\n",
        "index = SimpleIndex()\n",
        "\n",
        "all_docs = bangla_docs + english_docs\n",
        "\n",
        "for doc in all_docs:\n",
        "    index.add_document(doc)\n",
        "\n",
        "# Get statistics\n",
        "stats = index.get_stats()\n",
        "print(f\"\\n✓ Indexing complete!\")\n",
        "print(f\"  Total documents: {stats['total_documents']}\")\n",
        "print(f\"  Bangla documents: {stats['bangla_docs']}\")\n",
        "print(f\"  English documents: {stats['english_docs']}\")\n",
        "print(f\"  Unique terms: {stats['unique_terms']:,}\")\n",
        "\n",
        "# Save index\n",
        "print(\"\\nSaving index to disk...\")\n",
        "with open('simple_index.pkl', 'wb') as f:\n",
        "    pickle.dump(index, f)\n",
        "\n",
        "print(\"✓ Index saved to 'simple_index.pkl'\")\n",
        "print(\"\\nModule A complete! You can now run 'test_index.py' to test queries.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYCkYwFB5Nyh",
        "outputId": "b71a7822-e44e-4d3d-d6c0-56cfcc5f3b4c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading documents...\n",
            "Loaded 3094 Bangla + 3094 English documents\n",
            "\n",
            "Building inverted index...\n",
            "  Indexed 500 documents...\n",
            "  Indexed 1000 documents...\n",
            "  Indexed 1500 documents...\n",
            "  Indexed 2000 documents...\n",
            "  Indexed 2500 documents...\n",
            "  Indexed 3000 documents...\n",
            "  Indexed 3500 documents...\n",
            "  Indexed 4000 documents...\n",
            "  Indexed 4500 documents...\n",
            "  Indexed 5000 documents...\n",
            "  Indexed 5500 documents...\n",
            "  Indexed 6000 documents...\n",
            "\n",
            "✓ Indexing complete!\n",
            "  Total documents: 6188\n",
            "  Bangla documents: 3094\n",
            "  English documents: 3094\n",
            "  Unique terms: 57,829\n",
            "\n",
            "Saving index to disk...\n",
            "✓ Index saved to 'simple_index.pkl'\n",
            "\n",
            "Module A complete! You can now run 'test_index.py' to test queries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the index\n",
        "print(\"Loading index...\")\n",
        "with open('simple_index.pkl', 'rb') as f:\n",
        "    index = pickle.load(f)\n",
        "\n",
        "stats = index.get_stats()\n",
        "print(f\"✓ Index loaded successfully!\")\n",
        "print(f\"  Documents: {stats['total_documents']}\")\n",
        "print(f\"  Unique terms: {stats['unique_terms']:,}\\n\")\n",
        "\n",
        "# Test queries\n",
        "test_queries = [\n",
        "    \"cricket\",\n",
        "    \"নির্বাচন\",  # election\n",
        "    \"Bangladesh\",\n",
        "    \"ভারত\",  # India\n",
        "    \"university\",\n",
        "    \"সরকার\",  # government\n",
        "    \"police\",\n",
        "    \"খেলা\"  # game/sport\n",
        "]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"TESTING QUERIES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for query in test_queries:\n",
        "    results = index.search(query)\n",
        "\n",
        "    print(f\"\\nQuery: '{query}'\")\n",
        "    print(f\"Found: {len(results)} documents\")\n",
        "\n",
        "    if results:\n",
        "        # Show top 3 results\n",
        "        for i, doc in enumerate(results[:3], 1):\n",
        "            print(f\"\\n  [{i}] {doc['title'][:80]}\")\n",
        "            print(f\"      Language: {doc['language']}\")\n",
        "            print(f\"      Source: {doc['source']}\")\n",
        "            print(f\"      URL: {doc['url'][:60]}...\")\n",
        "\n",
        "            # Show named entities if available\n",
        "            if doc['named_entities']:\n",
        "                entities = doc['named_entities'][:5]  # Show first 5\n",
        "                print(f\"      Entities: {', '.join(entities)}\")\n",
        "    else:\n",
        "        print(\"  No results found\")\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "print(\"\\n✓ Testing complete!\")\n",
        "print(\"\\nTry your own queries:\")\n",
        "print(\"  >>> results = index.search('your query here')\")\n",
        "print(\"  >>> print(f'Found {len(results)} documents')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heE8Slze5RqA",
        "outputId": "5af3edc4-0af1-49a4-f280-624b28ad97b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading index...\n",
            "✓ Index loaded successfully!\n",
            "  Documents: 6188\n",
            "  Unique terms: 57,829\n",
            "\n",
            "============================================================\n",
            "TESTING QUERIES\n",
            "============================================================\n",
            "\n",
            "Query: 'cricket'\n",
            "Found: 90 documents\n",
            "\n",
            "  [1] Mahir Sarowar Megh: The 17-year-old designer of Durdanto Dhaka’s jersey\n",
            "      Language: en\n",
            "      Source: thedailystar\n",
            "      URL: https://www.thedailystar.net/rising-stars/stars-the-rise/new...\n",
            "      Entities: the Bangladesh Premier League, Megh, Odommo Jersey Design Contest, Ahsan Manzil, Shakib Al Hasan\n",
            "\n",
            "  [2] Team can only win if board officials are shown on TV during matches: study\n",
            "      Language: en\n",
            "      Source: thedailystar\n",
            "      URL: https://www.thedailystar.net/satireday/news/team-can-only-wi...\n",
            "      Entities: Abul, half, Cricket Board, Kamrul Hasan Phapa, Phapa\n",
            "\n",
            "  [3] It’s me, hi, I’m the problem, it’s me, says BCB boss\n",
            "      Language: en\n",
            "      Source: thedailystar\n",
            "      URL: https://www.thedailystar.net/satireday/news/its-me-hi-im-the...\n",
            "      Entities: Papon, Chandika Hathurusingha, T20I, Swift, Nazmul Hassan Papon\n",
            "------------------------------------------------------------\n",
            "\n",
            "Query: 'নির্বাচন'\n",
            "Found: 3151 documents\n",
            "\n",
            "  [1] ঢাকা-দিল্লি সম্পর্কে উত্তেজনা, ভারতীয় ভিসা কেন্দ্র আজ চালু থাকবে\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: https://www.prothomalo.com/bangladesh/rj5yhs7mhr...\n",
            "      Entities: থাকবে, ভিসা, হাইকমিশনারকে, তলবের, আজ\n",
            "\n",
            "  [2] দাম তো ৯ কোটির বেশি, নিয়মিত একাদশে জায়গা মিলবে কি মোস্তাফিজের\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: https://www.prothomalo.com/sports/cricket/bzrl6l96mv...\n",
            "      Entities: দাম, ৯, টেবিলে, মোস্তাফিজের, জায়গা\n",
            "\n",
            "  [3] তিন হাত বদলে অস্ত্র যায় নরসিংদীতে\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: https://www.prothomalo.com/bangladesh/crime/xnsmtz9tbm...\n",
            "      Entities: ও, যায়, গুলি, নরসিংদীতে, হাত\n",
            "------------------------------------------------------------\n",
            "\n",
            "Query: 'Bangladesh'\n",
            "Found: 1436 documents\n",
            "\n",
            "  [1] বিশ্ব গণমাধ্যমে বাঙালির বিজয়\n",
            "      Language: bn\n",
            "      Source: Dhaka Post\n",
            "      URL: https://www.dhakapost.com/opinion/417197...\n",
            "      Entities: অবস্থান, লুকাতে, ১৯৭১, অর্ধ, ঢাকায়\n",
            "\n",
            "  [2] ৬ষ্ঠ শ্রেণীর পড়াশোনা\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: http://www.prothom-alo.com/education/article/20048...\n",
            "      Entities: পরবর্তী, শিক্ষক, শিক্ষার্থী, শ্রেণীর, হবে\n",
            "\n",
            "  [3] জুনিয়র স্কুল সার্টিফিকেট পরীক্ষার প্রস্তুতি\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: http://www.prothom-alo.com/education/article/20620...\n",
            "      Entities: ও, ধরন, শুভেচ্ছা, সার্টিফিকেট, ১ম\n",
            "------------------------------------------------------------\n",
            "\n",
            "Query: 'ভারত'\n",
            "Found: 2884 documents\n",
            "\n",
            "  [1] ঢাকা-দিল্লি সম্পর্কে উত্তেজনা, ভারতীয় ভিসা কেন্দ্র আজ চালু থাকবে\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: https://www.prothomalo.com/bangladesh/rj5yhs7mhr...\n",
            "      Entities: থাকবে, ভিসা, হাইকমিশনারকে, তলবের, আজ\n",
            "\n",
            "  [2] দাম তো ৯ কোটির বেশি, নিয়মিত একাদশে জায়গা মিলবে কি মোস্তাফিজের\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: https://www.prothomalo.com/sports/cricket/bzrl6l96mv...\n",
            "      Entities: দাম, ৯, টেবিলে, মোস্তাফিজের, জায়গা\n",
            "\n",
            "  [3] তিন হাত বদলে অস্ত্র যায় নরসিংদীতে\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: https://www.prothomalo.com/bangladesh/crime/xnsmtz9tbm...\n",
            "      Entities: ও, যায়, গুলি, নরসিংদীতে, হাত\n",
            "------------------------------------------------------------\n",
            "\n",
            "Query: 'university'\n",
            "Found: 555 documents\n",
            "\n",
            "  [1] From Bangladesh to Panama: Bangladeshi robotics team clinches fifth position at \n",
            "      Language: en\n",
            "      Source: thedailystar\n",
            "      URL: https://www.thedailystar.net/campus/campus/news/bangladesh-p...\n",
            "      Entities: This year, 12, the \"Future Innovators (Senior, three months, WRO\n",
            "\n",
            "  [2] Power sector suffering for lack of a cohesive policy: experts\n",
            "      Language: en\n",
            "      Source: thedailystar\n",
            "      URL: https://www.thedailystar.net/business/news/power-sector-suff...\n",
            "      Entities: around 16,500 megawatts, 26,500 megawatts, Md Shahriar, last summer, Md Khalilur Rahman Khan\n",
            "\n",
            "  [3] Curbing deadly air pollution: 4 nations draw up roadmap\n",
            "      Language: en\n",
            "      Source: thedailystar\n",
            "      URL: https://www.thedailystar.net/environment/pollution/air-pollu...\n",
            "      Entities: as much as, Kyser, second, 30 percent, December 15\n",
            "------------------------------------------------------------\n",
            "\n",
            "Query: 'সরকার'\n",
            "Found: 3140 documents\n",
            "\n",
            "  [1] ঢাকা-দিল্লি সম্পর্কে উত্তেজনা, ভারতীয় ভিসা কেন্দ্র আজ চালু থাকবে\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: https://www.prothomalo.com/bangladesh/rj5yhs7mhr...\n",
            "      Entities: থাকবে, ভিসা, হাইকমিশনারকে, তলবের, আজ\n",
            "\n",
            "  [2] দাম তো ৯ কোটির বেশি, নিয়মিত একাদশে জায়গা মিলবে কি মোস্তাফিজের\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: https://www.prothomalo.com/sports/cricket/bzrl6l96mv...\n",
            "      Entities: দাম, ৯, টেবিলে, মোস্তাফিজের, জায়গা\n",
            "\n",
            "  [3] তিন হাত বদলে অস্ত্র যায় নরসিংদীতে\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: https://www.prothomalo.com/bangladesh/crime/xnsmtz9tbm...\n",
            "      Entities: ও, যায়, গুলি, নরসিংদীতে, হাত\n",
            "------------------------------------------------------------\n",
            "\n",
            "Query: 'police'\n",
            "Found: 227 documents\n",
            "\n",
            "  [1] On the campaign trail in a tug-of-war Myanmar town\n",
            "      Language: en\n",
            "      Source: Dhaka Tribune\n",
            "      URL: https://www.dhakatribune.com/world/asia/398885/on-the-campai...\n",
            "      Entities: second, around a third, Pyin Oo Lwin, Myanmar, late 2023\n",
            "\n",
            "  [2] Trump says Ukraine deal close, Europe proposes peace force\n",
            "      Language: en\n",
            "      Source: Dhaka Tribune\n",
            "      URL: https://www.dhakatribune.com/world/europe/398854/trump-says-...\n",
            "      Entities: the Oval Office, Kyiv, Ukraine, Washington, Institute for the Study of War\n",
            "\n",
            "  [3] Pakistani court hands 35-year jail to cleric of banned group for inciting violen\n",
            "      Language: en\n",
            "      Source: Dhaka Tribune\n",
            "      URL: https://www.dhakatribune.com/world/south-asia/398853/pakista...\n",
            "      Entities: Maqsood-ul-Haq, Tuesday, 35-year, 35 years, 1974\n",
            "------------------------------------------------------------\n",
            "\n",
            "Query: 'খেলা'\n",
            "Found: 3119 documents\n",
            "\n",
            "  [1] ঢাকা-দিল্লি সম্পর্কে উত্তেজনা, ভারতীয় ভিসা কেন্দ্র আজ চালু থাকবে\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: https://www.prothomalo.com/bangladesh/rj5yhs7mhr...\n",
            "      Entities: থাকবে, ভিসা, হাইকমিশনারকে, তলবের, আজ\n",
            "\n",
            "  [2] দাম তো ৯ কোটির বেশি, নিয়মিত একাদশে জায়গা মিলবে কি মোস্তাফিজের\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: https://www.prothomalo.com/sports/cricket/bzrl6l96mv...\n",
            "      Entities: দাম, ৯, টেবিলে, মোস্তাফিজের, জায়গা\n",
            "\n",
            "  [3] তিন হাত বদলে অস্ত্র যায় নরসিংদীতে\n",
            "      Language: bn\n",
            "      Source: Prothom Alo\n",
            "      URL: https://www.prothomalo.com/bangladesh/crime/xnsmtz9tbm...\n",
            "      Entities: ও, যায়, গুলি, নরসিংদীতে, হাত\n",
            "------------------------------------------------------------\n",
            "\n",
            "✓ Testing complete!\n",
            "\n",
            "Try your own queries:\n",
            "  >>> results = index.search('your query here')\n",
            "  >>> print(f'Found {len(results)} documents')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download all generated files to your computer\n",
        "from google.colab import files\n",
        "\n",
        "files.download('bangla_articles_with_ner.json')\n",
        "files.download('english_articles_with_ner.json')\n",
        "files.download('simple_index.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EexQCz0q55vM",
        "outputId": "00deb39b-18bf-4093-8853-9e998e27486e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cc170b73-e6da-447f-b261-14f0906e2707\", \"bangla_articles_with_ner.json\", 17381248)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8e686081-cc3d-432e-a868-bafc1b08aebf\", \"english_articles_with_ner.json\", 17949390)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aec5baa3-c3ba-45b0-b1e4-cff5cd257d10\", \"simple_index.pkl\", 17990496)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}